{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/hotel_bookings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction of Cancellation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = ['lead_time', 'hotel', 'market_segment', 'previous_cancellations', \n",
    "            'booking_changes', 'total_of_special_requests', 'arrival_date_month']\n",
    "df_cancellation = df[features + ['is_canceled']].dropna()\n",
    "\n",
    "label_encoders = {}\n",
    "for col in ['hotel', 'market_segment', 'arrival_date_month']:\n",
    "    le = LabelEncoder()\n",
    "    df_cancellation[col] = le.fit_transform(df_cancellation[col])\n",
    "    label_encoders[col] = le\n",
    "df_cancellation['is_canceled'] = df_cancellation['is_canceled'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "X = df_cancellation[features]\n",
    "y = df_cancellation['is_canceled']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task Type: Classification Problem Yes or No\n",
    "\n",
    "Why choosing these models ?\n",
    "\n",
    "- Logistic Regression - for binary outcomes\n",
    "- RFC - handle complex patterns and interactions between features for categorical predictions.\n",
    "- DTC - make decisions on categorical labels \n",
    "\n",
    "Model Output:\n",
    "\n",
    "- The output is a label or category, such as \"Yes\" (1) or \"No\" (0). The classification models work to assign probabilities to each label and classify data points based on these probabilities.\n",
    "\n",
    "Evaluation Metrics:\n",
    "\n",
    "- Metrics such as accuracy, precision, recall, and F1-score are used to evaluate how well the model predicts the correct category.\n",
    "- These metrics are relevant for measuring how many bookings are accurately predicted as \"canceled\" or \"not canceled.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to train and evaluate a model\n",
    "def train_and_evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    return accuracy, report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest\n",
      "Accuracy: 80.74%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85     22478\n",
      "           1       0.76      0.70      0.73     13339\n",
      "\n",
      "    accuracy                           0.81     35817\n",
      "   macro avg       0.80      0.79      0.79     35817\n",
      "weighted avg       0.81      0.81      0.81     35817\n",
      "\n",
      "------------------------------------------------------------\n",
      "Model: Logistic Regression\n",
      "Accuracy: 72.67%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.88      0.80     22478\n",
      "           1       0.70      0.47      0.56     13339\n",
      "\n",
      "    accuracy                           0.73     35817\n",
      "   macro avg       0.72      0.67      0.68     35817\n",
      "weighted avg       0.72      0.73      0.71     35817\n",
      "\n",
      "------------------------------------------------------------\n",
      "Model: Decision Tree\n",
      "Accuracy: 80.31%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.85     22478\n",
      "           1       0.76      0.68      0.72     13339\n",
      "\n",
      "    accuracy                           0.80     35817\n",
      "   macro avg       0.79      0.78      0.78     35817\n",
      "weighted avg       0.80      0.80      0.80     35817\n",
      "\n",
      "------------------------------------------------------------\n",
      "Model: Gradient Boosting\n",
      "Accuracy: 77.15%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83     22478\n",
      "           1       0.73      0.61      0.66     13339\n",
      "\n",
      "    accuracy                           0.77     35817\n",
      "   macro avg       0.76      0.74      0.75     35817\n",
      "weighted avg       0.77      0.77      0.77     35817\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Models to evaluate\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    accuracy, report = train_and_evaluate_model(model, X_train, X_test, y_train, y_test)\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Average Daily Rate (ADR) or Revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task Type: Regression problem, where the goal is to predict a continuous numerical value\n",
    "\n",
    "Why choosing these models ?\n",
    "- Linear Regression: The simplest regression model that tries to fit a line to explain the relationship between input features and the output.\n",
    "- Random Forest Regressor and Gradient Boosting Regressor: These models handle complex relationships and non-linear patterns well, which is useful for predicting a continuous value like ADR.\n",
    "- Decision Tree Regressor: A tree-based approach to predict continuous values.\n",
    "\n",
    "Model Outputs:\n",
    "\n",
    "- The output is a continuous numerical value, such as the predicted ADR. Regression models are designed to minimize the error between predicted values and the true continuous values.\n",
    "\n",
    "Evaluation Metrics:\n",
    "- Metrics such as Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared (R²) are used to evaluate how close the predicted numerical values are to the actual ADR values.\n",
    "- These metrics help in understanding the model's accuracy in predicting the continuous target variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adr_features = ['hotel', 'lead_time', 'market_segment', 'arrival_date_month',\n",
    "                'previous_cancellations', 'booking_changes', 'total_of_special_requests', 'is_repeated_guest']\n",
    "\n",
    "adr_df = df[adr_features + ['adr']].dropna()\n",
    "for col in ['hotel', 'market_segment', 'arrival_date_month']:\n",
    "    adr_df[col] = label_encoders[col].transform(adr_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_adr = adr_df[adr_features]\n",
    "y_adr = adr_df['adr']\n",
    "X_train_adr, X_test_adr, y_train_adr, y_test_adr = train_test_split(X_adr, y_adr, test_size=0.3, random_state=42)\n",
    "\n",
    "# Function to train and evaluate regression models\n",
    "def train_and_evaluate_regression(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = root_mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    return mae, mse, r2\n",
    "\n",
    "# Regression models to evaluate\n",
    "regression_models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree Regressor': DecisionTreeRegressor(random_state=42),\n",
    "    'Random Forest Regressor': RandomForestRegressor(random_state=42),\n",
    "    'Gradient Boosting Regressor': GradientBoostingRegressor(random_state=42)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Daily Rate (ADR) Prediction Results:\n",
      "\n",
      "Model: Linear Regression\n",
      "Mean Absolute Error (MAE): 33.76\n",
      "Mean Squared Error (MSE): 45.61\n",
      "R-squared (R²): 0.10\n",
      "------------------------------------------------------------\n",
      "Model: Decision Tree Regressor\n",
      "Mean Absolute Error (MAE): 21.23\n",
      "Mean Squared Error (MSE): 40.47\n",
      "R-squared (R²): 0.29\n",
      "------------------------------------------------------------\n",
      "Model: Random Forest Regressor\n",
      "Mean Absolute Error (MAE): 19.77\n",
      "Mean Squared Error (MSE): 34.37\n",
      "R-squared (R²): 0.49\n",
      "------------------------------------------------------------\n",
      "Model: Gradient Boosting Regressor\n",
      "Mean Absolute Error (MAE): 24.42\n",
      "Mean Squared Error (MSE): 34.18\n",
      "R-squared (R²): 0.50\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate each regression model\n",
    "print(\"Average Daily Rate (ADR) Prediction Results:\\n\")\n",
    "for model_name, model in regression_models.items():\n",
    "    mae, mse, r2 = train_and_evaluate_regression(model, X_train_adr, X_test_adr, y_train_adr, y_test_adr)\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "    print(f\"R-squared (R²): {r2:.2f}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Best Parameters: {'subsample': 0.8, 'n_estimators': 300, 'min_samples_split': 10, 'min_samples_leaf': 9, 'max_depth': 9, 'learning_rate': 0.05}\n",
      "Mean Absolute Error (MAE): 20.12\n",
      "Mean Squared Error (MSE): 31.31\n",
      "R-squared (R²): 0.58\n"
     ]
    }
   ],
   "source": [
    "gbr = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Defining the parameter space to search\n",
    "param_dist = {\n",
    "    'n_estimators': np.arange(100, 500, 100),\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': np.arange(3, 10),\n",
    "    'min_samples_split': np.arange(2, 15, 2),\n",
    "    'min_samples_leaf': np.arange(1, 10),\n",
    "    'subsample': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Setting up the RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=gbr, param_distributions=param_dist, \n",
    "                                   n_iter=50, cv=3, n_jobs=-1, scoring='neg_mean_squared_error', verbose=2, random_state=42)\n",
    "\n",
    "\n",
    "random_search.fit(X_train_adr, y_train_adr)\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_adr)\n",
    "\n",
    "mae = mean_absolute_error(y_test_adr, y_pred)\n",
    "mse = root_mean_squared_error(y_test_adr, y_pred)\n",
    "r2 = r2_score(y_test_adr, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"R-squared (R²): {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Booking Modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_features = ['lead_time', 'hotel', 'market_segment', 'previous_cancellations', \n",
    "                'total_of_special_requests', 'arrival_date_month', 'is_repeated_guest']\n",
    "mod_df = df[mod_features + ['booking_changes']].dropna()\n",
    "for col in ['hotel', 'market_segment', 'arrival_date_month']:\n",
    "    mod_df[col] = label_encoders[col].transform(mod_df[col])\n",
    "mod_df['booking_changes_binary'] = mod_df['booking_changes'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 84.75%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92     30359\n",
      "           1       0.20      0.00      0.00      5458\n",
      "\n",
      "    accuracy                           0.85     35817\n",
      "   macro avg       0.52      0.50      0.46     35817\n",
      "weighted avg       0.75      0.85      0.78     35817\n",
      "\n",
      "------------------------------------------------------------\n",
      "Model: Random Forest\n",
      "Accuracy: 83.86%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     30359\n",
      "           1       0.45      0.26      0.33      5458\n",
      "\n",
      "    accuracy                           0.84     35817\n",
      "   macro avg       0.66      0.60      0.62     35817\n",
      "weighted avg       0.81      0.84      0.82     35817\n",
      "\n",
      "------------------------------------------------------------\n",
      "Model: Gradient Boosting\n",
      "Accuracy: 84.86%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92     30359\n",
      "           1       0.74      0.01      0.02      5458\n",
      "\n",
      "    accuracy                           0.85     35817\n",
      "   macro avg       0.79      0.50      0.47     35817\n",
      "weighted avg       0.83      0.85      0.78     35817\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_mod = mod_df[mod_features]\n",
    "y_mod = mod_df['booking_changes_binary']\n",
    "X_train_mod, X_test_mod, y_train_mod, y_test_mod = train_test_split(X_mod, y_mod, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define and train classification models\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in classifiers.items():\n",
    "    model.fit(X_train_mod, y_train_mod)\n",
    "    y_pred_mod = model.predict(X_test_mod)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test_mod, y_pred_mod)\n",
    "    report = classification_report(y_test_mod, y_pred_mod)\n",
    "    \n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to Adjust Class Imbalance\n",
    "- Resampling \n",
    "    - Oversampling the minority class (modifications) using techniques like SMOTE (Synthetic Minority Over-sampling Technique) or random oversampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 61.93%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.64      0.74     30359\n",
      "           1       0.20      0.49      0.28      5458\n",
      "\n",
      "    accuracy                           0.62     35817\n",
      "   macro avg       0.54      0.56      0.51     35817\n",
      "weighted avg       0.77      0.62      0.67     35817\n",
      "\n",
      "------------------------------------------------------------\n",
      "Model: Random Forest\n",
      "Accuracy: 70.70%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.74      0.81     30359\n",
      "           1       0.27      0.52      0.35      5458\n",
      "\n",
      "    accuracy                           0.71     35817\n",
      "   macro avg       0.58      0.63      0.58     35817\n",
      "weighted avg       0.80      0.71      0.74     35817\n",
      "\n",
      "------------------------------------------------------------\n",
      "Model: Gradient Boosting\n",
      "Accuracy: 64.08%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.66      0.76     30359\n",
      "           1       0.22      0.53      0.31      5458\n",
      "\n",
      "    accuracy                           0.64     35817\n",
      "   macro avg       0.55      0.60      0.53     35817\n",
      "weighted avg       0.79      0.64      0.69     35817\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_mod, y_train_mod)\n",
    "# Define and train classification models\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in classifiers.items():\n",
    "    model.fit(X_resampled, y_resampled)\n",
    "    y_pred_mod = model.predict(X_test_mod)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test_mod, y_pred_mod)\n",
    "    report = classification_report(y_test_mod, y_pred_mod)\n",
    "    \n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7}\n",
      "Accuracy: 84.76%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92     30359\n",
      "           1       0.43      0.00      0.00      5458\n",
      "\n",
      "    accuracy                           0.85     35817\n",
      "   macro avg       0.64      0.50      0.46     35817\n",
      "weighted avg       0.78      0.85      0.78     35817\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 3, 5]\n",
    "}\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=RandomForestClassifier(random_state=42), param_distributions=param_dist,\n",
    "                                   n_iter=50, cv=3, n_jobs=-1, scoring='recall', random_state=42)\n",
    "\n",
    "random_search.fit(X_train_mod, y_train_mod)\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred_mod = best_model.predict(X_test_mod)\n",
    "accuracy = accuracy_score(y_test_mod, y_pred_mod)\n",
    "report = classification_report(y_test_mod, y_pred_mod)\n",
    "print(f\"Best Parameters: {random_search.best_params_}\")\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
